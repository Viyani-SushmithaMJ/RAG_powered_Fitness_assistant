{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1 : Import Necessary Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.46.2)\n",
      "Requirement already satisfied: sentence-transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: faiss-cpu in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: PyMuPDF in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.24.14)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (2.2.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentence-transformers faiss-cpu PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2 : Load the folder with documents/Data and chunk it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    \"\"\"Split text into smaller chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# Read and chunk PDF documents\n",
    "pdf_folder = \"/teamspace/studios/this_studio/PDFs\"  \n",
    "document_chunks = []\n",
    "chunk_index_mapping = {}\n",
    "\n",
    "for pdf_file in os.listdir(pdf_folder):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(os.path.join(pdf_folder, pdf_file))\n",
    "        chunks = chunk_text(text)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            document_chunks.append(chunk)\n",
    "            chunk_index_mapping[len(document_chunks) - 1] = {\n",
    "                \"file\": pdf_file,\n",
    "                \"section\": chunk\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3 : Convert Chunks into Embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046832f70b3c43acb150c94cfdc55f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb48b4fe70a54d75a0678c32baf839da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adbfaecb76f44ac8682e336be6b1e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d3e05b52e14b13b139d57a3636dc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c6e1a1b0ee44698d4e30c445f48a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ac91da7f7d4cd99da24eb9bc03a584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409c0b3478bd4c45bb13e8c1ea307d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad54f3344f8471d812ea9232d6a76bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a83e3f16674ab09aaa669470617d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb1ce70e3d3427da41ef09ff9a5049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd7a9bed4334ab98502298ec7bdbd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Generate embeddings for document chunks\n",
    "chunk_embeddings = embedding_model.encode(document_chunks, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 4 :  Store Embeddings in a Vector Database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# InitializeingFAISS index\n",
    "dimension = chunk_embeddings.shape[1]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add embeddings to the FAISS index\n",
    "faiss_index.add(chunk_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5 :   Retrieve Relevant Chunks with similarity threshold of 0.5  Based on User Query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def retrieve_relevant_sections(query, top_k=3, similarity_threshold=0.5):\n",
    "    \"\"\"Retrieve top-k relevant sections based on the query.\"\"\"\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    \n",
    "    # Extract relevant sections from data with a similarity threshold filter\n",
    "    relevant_sections = []\n",
    "    for idx in indices[0]:\n",
    "        if idx != -1:\n",
    "            section = chunk_index_mapping[idx]\n",
    "            # Calculate similarity between query and the retrieved section text\n",
    "            section_embedding = embedding_model.encode([section['section']], convert_to_numpy=True)\n",
    "            similarity_score = cosine_similarity([query_embedding[0]], [section_embedding[0]])[0][0]\n",
    "            if similarity_score > similarity_threshold:\n",
    "                relevant_sections.append(section)\n",
    "    return relevant_sections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 6 :   Selection of Model, Uses a Hugging Face LLM to generate a human-like response.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcf5a39daad417f8f2a0b8e08b9255a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7c27b093ba4768ab63ff1f7e7a9870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298b8b419c874d5db3ad0c5b02462883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fd739c19ab45988980ea8b12f8df84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c31cd5cd9564a7f9a0e7e7febf4041f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6af37f52587410aa83c82a7f013061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# Load Hugging Face model\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"  \n",
    "response_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "response_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "if response_tokenizer.pad_token is None:\n",
    "    response_tokenizer.pad_token = response_tokenizer.eos_token  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_similarity(query, response):\n",
    "    \"\"\"Calculate similarity score between the query and the response.\"\"\"\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    response_embedding = embedding_model.encode([response], convert_to_numpy=True)\n",
    "    similarity_score = cosine_similarity(query_embedding, response_embedding)[0][0]\n",
    "    return similarity_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 7 :   Generate answer/response function to query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, relevant_sections):\n",
    "    \"\"\"Generate a response using the query and retrieved sections.\"\"\"\n",
    "    # Combine the relevant sections into context\n",
    "    context = \"\\n\".join([f\"From {section['file']}:\\n{section['section']}\" for section in relevant_sections])\n",
    "    \n",
    "    # Custom prompt \n",
    "    input_text = f\"Based on the context below,  answer to the query in less than 500 words in length without repeating any information.\\n\\nContext: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    # Tokenize input text\n",
    "    inputs = response_tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    )\n",
    "    \n",
    "    # Generate the response\n",
    "    outputs = response_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=200,\n",
    "        pad_token_id=response_tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode and return the generated answer\n",
    "    answer = response_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 8 :  To filter the response with perplexity, similarity score and custom prompts - to set quality of response in prior to presenting to user*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_response(response, query, max_perplexity=15, min_similarity=0.4):\n",
    "    \"\"\"Auto-check and filter the generated response based on perplexity and similarity.\"\"\"\n",
    "    # Check perplexity\n",
    "    perplexity_score = evaluate_perplexity(response)\n",
    "    if perplexity_score > max_perplexity:\n",
    "        return \"The response generated is too uncertain. Please try again or please reframe your question.\"\n",
    "\n",
    "    # Check similarity with the query\n",
    "    similarity_score = evaluate_similarity(query, response)\n",
    "    if similarity_score < min_similarity:\n",
    "        return \"The response seems irrelevant to your question. Please try again or please reframe your question.\"\n",
    "\n",
    "    # Return the valid response\n",
    "    return response\n",
    "\n",
    "def answer_query(query, top_k=1):\n",
    "    \"\"\"Retrieve relevant sections, generate a response, and filter it.\"\"\"\n",
    "    # Retrieve relevant sections\n",
    "    relevant_sections = retrieve_relevant_sections(query, top_k=top_k)\n",
    "    if not relevant_sections:\n",
    "        return \"Sorry, I couldn't find relevant information.Please try another query or  reframe your question\"\n",
    "    \n",
    "    # Generate the response\n",
    "    response = generate_answer(query, relevant_sections)\n",
    "    \n",
    "    # Auto-check and filter the response\n",
    "    filtered_response = filter_response(response, query)\n",
    "    \n",
    "    return filtered_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer for perplexity evaluation\n",
    "perplexity_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "perplexity_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def evaluate_perplexity(response):\n",
    "    inputs = perplexity_tokenizer(response, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = perplexity_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss).item()\n",
    "    return perplexity\n",
    "\n",
    "# Example\n",
    "#response = \"The best exercises for muscle gain include squats, deadlifts, and bench presses.\"\n",
    "perplexity_score = evaluate_perplexity(response)\n",
    "print(f\"Perplexity Score: {perplexity_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 9 :  User Query Samples Section*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      " Based on the context below,  answer to the query in less than 500 words in length without repeating any information.\n",
      "\n",
      "Context: From fitness_guide.pdf:\n",
      "Fitness Workout Guide 1.​ Fitness Guide 1.1.​ A Beginner Workout Plan Starting a fitness journey as a beginner is a transformative step towards a healthier, stronger you. Having the right mindset and strategies can significantly impact your success. Here are some valuable tips to get you started: ●​ Start Slowly. Don't try to do too much too soon. If you're new to working out, start with a few days a week and gradually increase the frequency and intensity of your workouts as you get stronger. ●​ Listen to Your Body. If you're feeling pain, stop and rest. Don't push yourself too hard, especially in the beginning. ●​ Find a Workout Buddy. Working out with a friend can help you stay motivated and accountable. ●​ Make it Fun. You're less likely to stick with your workouts if you're not enjoying them. Find activities that you enjoy and that challenge you. As you embark on your fitness journey, remember that every step is a commitment to yourself. You can make meaningful progress by starting slowly, listening to your body, finding a workout buddy, and infusing fun into your fitness routine. By putting yourself first, you can overcome challenges and confidently embrace your journey, creating a healthy, strong, and vibrant you! The Importance of a Dynamic Warm-Up Before you begin exercising, dedicating time to a dynamic warm-up is pivotal, especially when you're a beginner at the gym. Begin with a brisk 5-minute walk, allowing your muscles to gradually wake up. Follow up with leg swings that increase blood flow and improve flexibility. Ankle rotations further prepare your lower body, ensuring your joints are primed for action. Exercise Types to Include in a Beginner Workout Plan A well-rounded beginner workout plan should include a variety of exercises that target all the major muscle groups. This will help you build strength, endurance, and flexibility. Strength Training: Strength training exercises help build muscle and bone mass. Some good strength training exercises for beginners include: ●​ Squats ●​ Lunges ●​ Push-ups ●​ Pull-ups ●​ Planks ●​ Crunches ●​ Leg raises Cardio: Cardio exercises help to improve cardiovascular health and burn calories. Some good cardio exercises for beginners include: ●​ Walking ●​ Jogging ●​ Running ●​ Biking ●​ Swimming ●​ Jumping rope ●​ Hiking Stretching & Mobility: Stretching and mobility exercises help to improve flexibility and range of motion. They are also important for preventing injuries. Some good stretching and mobility exercises for beginners include: ●​ Dynamic stretches ●​ Static stretches ●​ Foam rolling It is important to include a variety of exercise types in your workout plan to get the most benefits. You should also start with low weights and high reps when strength training, gradually increasing the weight and intensity as you get stronger. And don't forget to warm up and cool down before and after your workouts to prevent injuries. Your Beginner Workout Plan Now you understand the high-level basics of creating a gym routine for beginners, here’s our favorite combination of all you’ll need\n",
      "\n",
      "Query: what are the expert tips for beginners at gym?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Context: From fitness_guide.pdf:\n",
      "Fitness Workout Guide 1.​ Fitness Guide 1.1.​ A Beginner Workout Plan Starting a fitness journey as a beginner is a transformative step towards a healthier, stronger you. Having the right mindset and strategies can significantly impact your success. Here are some valuable tips to get you started: ●​ Start Slowly. Don't try to do too much too soon. If you're new to working out, start with a few days a week and gradually increase the frequency and intensity of your workouts as you get stronger. ●​ Listen to Your Body. If you're feeling pain, stop and rest. Don't push yourself too hard, especially in the beginning. ●​ Find a Workout Buddy. Working out with a friend can help you stay motivated and accountable. ●​ Make it Fun. You're less likely to stick with your workouts if you're not enjoying them. Find activities that you enjoy and that challenge you.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"what are the expert tips for beginners at gym?\"\n",
    "response = answer_query(user_query)\n",
    "print(\"\\nResponse:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 10 :  Performance metrics response time , similarity score and perplexity score can be viewed for each query*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Time: 39.06 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Measure response time\n",
    "start_time = time.time()\n",
    "response = answer_query(user_query)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\nResponse Time: {:.2f} seconds\".format(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5004d00f6b849ca8da674855cc93590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89f471a3f7343a8ba7c239282726ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0409a6dc46554561bfa63448116ded83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2479eabb0e4dbfb36aca46ed63dc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6787c72b5e44cab08f2130e7ea5b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aae2efcb478458b9e27901e92a26d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a65f0d0bbe4eefa5aa1fb8233877d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1685aed7576b400eb853b6129447ebe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e629d4f4954fc8ae4b16b344238f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509fae1d121e4a7d904f1ec9c63f1547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26066cb3d21842c992fc7061458e6aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.59\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load embedding model\n",
    "similarity_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def evaluate_similarity(query, response):\n",
    "    query_embedding = similarity_model.encode(query, convert_to_numpy=True)\n",
    "    response_embedding = similarity_model.encode(response, convert_to_numpy=True)\n",
    "    similarity = cosine_similarity([query_embedding], [response_embedding])\n",
    "    return similarity[0][0]\n",
    "\n",
    "similarity_score = evaluate_similarity(user_query, response)\n",
    "print(f\"Similarity Score: {similarity_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity Score: 8.87\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer for perplexity evaluation\n",
    "perplexity_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "perplexity_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def evaluate_perplexity(response):\n",
    "    inputs = perplexity_tokenizer(response, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = perplexity_model(**inputs, labels=inputs[\"input_ids\"])\n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss).item()\n",
    "    return perplexity\n",
    "\n",
    "# Example\n",
    "#response = \"The best exercises for muscle gain include squats, deadlifts, and bench presses.\"\n",
    "perplexity_score = evaluate_perplexity(response)\n",
    "print(f\"Perplexity Score: {perplexity_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
